{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate the features generated with Spark Workflow vs ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the features from a parquet generated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sqlContext.read.format(\"parquet\").load(\"file:/Users/vk/data/ML_MP_JR/ttbar_lepFilter_13TeV/ttbar_features_950.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|           hfeatures|           lfeatures|\n",
      "+--------------------+--------------------+\n",
      "|[373.637100219726...|[WrappedArray(126...|\n",
      "|[200.109180450439...|[WrappedArray(112...|\n",
      "|[267.100757598876...|[WrappedArray(70....|\n",
      "|[235.573299407958...|[WrappedArray(114...|\n",
      "|[268.110122680664...|[WrappedArray(163...|\n",
      "|[154.009853363037...|[WrappedArray(34....|\n",
      "|[43.8011703491210...|[WrappedArray(52....|\n",
      "|[355.839591979980...|[WrappedArray(192...|\n",
      "|[498.655937194824...|[WrappedArray(150...|\n",
      "|[405.600200653076...|[WrappedArray(125...|\n",
      "|[0.0, 22.88990783...|[WrappedArray(28....|\n",
      "|[323.521884918212...|[WrappedArray(182...|\n",
      "|[83.6020126342773...|[WrappedArray(25....|\n",
      "|[215.075908660888...|[WrappedArray(70....|\n",
      "|[333.586856842041...|[WrappedArray(57....|\n",
      "|[153.549125671386...|[WrappedArray(83....|\n",
      "|[522.556297302246...|[WrappedArray(173...|\n",
      "|[226.487812042236...|[WrappedArray(72....|\n",
      "|[0.0, 46.76742172...|[WrappedArray(364...|\n",
      "|[232.679992675781...|[WrappedArray(131...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 14)\n",
      "(10, 801, 19)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Take the first 10 rows and convert that into numpy array\n",
    "#\n",
    "sample_features = features.take(10)\n",
    "sample_hfeatures = np.asarray([row.hfeatures for row in sample_features])\n",
    "sample_lfeatures = np.asarray([np.asarray(row.lfeatures) for row in sample_features])\n",
    "print sample_hfeatures.shape\n",
    "print sample_lfeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.73637e+02   1.40337e+02   2.67839e+00   4.41126e+04   3.00000e+00\n",
      "   2.00000e+00   1.24368e+02   1.74327e-01  -1.76712e+00   2.24426e-02\n",
      "   0.00000e+00   0.00000e+00   1.00000e+00   1.00000e+00]\n"
     ]
    }
   ],
   "source": [
    "print sample_hfeatures[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the hdf5 file and obtain the pre-generated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5FileName = \"/Users/vk/data/ML_MP_JR/ttbar_lepFilter_13TeV/ttbar_lepFilter_13TeV_950.h5\"\n",
    "f = h5py.File(hdf5FileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3616, 801, 19)\n",
      "(3616, 14)\n"
     ]
    }
   ],
   "source": [
    "h5_lfeatures = f[\"Particles\"][..., 1:]\n",
    "h5_hfeatures = f[\"HLF\"][:, 1:]\n",
    "print h5_lfeatures.shape\n",
    "print h5_hfeatures.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the arrays directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.12746e+02   5.68923e+01  -2.28131e+01   9.46277e+01   6.12958e+01\n",
      "   1.21881e+00  -3.81357e-01   0.00000e+00   0.00000e+00   0.00000e+00\n",
      "   0.00000e+00   0.00000e+00   2.62018e-02   0.00000e+00   0.00000e+00\n",
      "   0.00000e+00   0.00000e+00   1.00000e+00  -1.00000e+00]\n"
     ]
    }
   ],
   "source": [
    "print h5_lfeatures[1, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.12746e+02   5.68923e+01  -2.28131e+01   9.46277e+01   6.12958e+01\n",
      "   1.21881e+00  -3.81357e-01   0.00000e+00   0.00000e+00   0.00000e+00\n",
      "   0.00000e+00   0.00000e+00   2.62018e-02   0.00000e+00   0.00000e+00\n",
      "   0.00000e+00   0.00000e+00   1.00000e+00  -1.00000e+00]\n"
     ]
    }
   ],
   "source": [
    "print sample_lfeatures[1, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.00109e+02   3.62160e+01  -2.73218e+00   1.82790e+04   3.00000e+00\n",
      "   2.00000e+00   6.12958e+01   1.21881e+00  -3.81357e-01   0.00000e+00\n",
      "   0.00000e+00   2.62018e-02  -1.00000e+00   0.00000e+00]\n"
     ]
    }
   ],
   "source": [
    "print h5_hfeatures[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.00109e+02   3.62160e+01  -2.73218e+00   7.56226e+03   3.00000e+00\n",
      "   2.00000e+00   6.12958e+01   1.21881e+00  -3.81357e-01   0.00000e+00\n",
      "   0.00000e+00   2.62018e-02  -1.00000e+00   0.00000e+00]\n"
     ]
    }
   ],
   "source": [
    "print sample_hfeatures[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
